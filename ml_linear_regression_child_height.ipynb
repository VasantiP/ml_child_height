{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9086b9",
   "metadata": {},
   "source": [
    "# Linear Regression Modeling of Child Height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b377e5",
   "metadata": {},
   "source": [
    "Outline: \n",
    "1. Load and explore the dataset: shape, datatypes, missing values in data\n",
    "2. Clean and Proprocess:\n",
    "   - Label encode sex\n",
    "   - Create additional features:\n",
    "       - interaction terms\n",
    "       - polynomial terms\n",
    "       - percentiles\n",
    "3. Visualize data\n",
    "4. Build models:\n",
    "   - Create models with different features\n",
    "   - Partition data into training and test subsets\n",
    "   - Scale and normalize mean\n",
    "   - Fit models\n",
    "   - Calculate metrics: R2, RMSE, MAE\n",
    "5. Compare models\n",
    "6. Analyze best model:\n",
    "   - check assumptions of linear regression are satisfied\n",
    "   - check feature importance\n",
    "8. Make predictions with prediction and confidence intervals\n",
    "   - calculate the prediction with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f1a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ba471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and explore data\n",
    "def explore_data(df):\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumn info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nBasic statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    \n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"Load and perform initial exploration of the dataset\"\"\"\n",
    "    print(\"Loading dataset...\")\n",
    "    # import dataset as a pandas DataFrame.\n",
    "    df = pd.read_csv(file_path)\n",
    "    explore_data(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa365c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'galton.csv'\n",
    "df = load_and_explore_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean and Preprocess\n",
    "def clean_and_preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess the data\"\"\"\n",
    "    print(\"\\nCleaning and preprocessing data...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Handle missing values (if any)\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    # Encode sex variable\n",
    "    le_sex = LabelEncoder()\n",
    "    df_clean['sex_encoded'] = le_sex.fit_transform(df_clean['sex'])\n",
    "    \n",
    "    # Create interaction terms\n",
    "    df_clean['avg_parent_height'] = (df_clean['father'] + df_clean['mother']) / 2\n",
    "    df_clean['height_diff_parents'] = df_clean['father'] - df_clean['mother']\n",
    "    df_clean['father_x_mother'] = df_clean['father'] * df_clean['mother']\n",
    "\n",
    "    # Create polynomial features\n",
    "    df_clean['father_sqrt'] = df_clean['father']**(0.5)\n",
    "    \n",
    "    # Create height percentiles within sex groups\n",
    "    df_clean['height_percentile'] = df_clean.groupby('sex')['height'].rank(pct=True)\n",
    "    \n",
    "    print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "    print(f\"Sex encoding: {dict(zip(le_sex.classes_, le_sex.transform(le_sex.classes_)))}\")\n",
    "    \n",
    "    return df_clean, le_sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess\n",
    "df_clean, label_encoder = clean_and_preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "def create_visualizations(df):\n",
    "    \"\"\"Create comprehensive visualizations\"\"\"\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    \n",
    "    # Set up the plotting area\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Distribution of heights by sex\n",
    "    plt.subplot(3, 4, 1)\n",
    "    sns.histplot(data=df, x='height', hue='sex', kde=True, alpha=0.7)\n",
    "    plt.title('Distribution of Kids Heights by Sex')\n",
    "    plt.xlabel('Height')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # 2. Scatter plot: Father vs Kid height\n",
    "    plt.subplot(3, 4, 2)\n",
    "    sns.scatterplot(data=df, x='father', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Father Height vs Kid Height')\n",
    "    plt.xlabel('Father Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "    \n",
    "    # 3. Scatter plot: Mother vs Kid height\n",
    "    plt.subplot(3, 4, 3)\n",
    "    sns.scatterplot(data=df, x='mother', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Mother Height vs Kid Height')\n",
    "    plt.xlabel('Mother Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "    \n",
    "    # 4. Average parent height vs kid height\n",
    "    plt.subplot(3, 4, 4)\n",
    "    sns.scatterplot(data=df, x='avg_parent_height', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Average Parent Height vs Kid Height')\n",
    "    plt.xlabel('Average Parent Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "    \n",
    "    # 5. Correlation heatmap\n",
    "    plt.subplot(3, 4, 5)\n",
    "    numeric_cols = ['father', 'mother', 'height', 'nkids', 'sex_encoded', 'avg_parent_height', 'height_diff_parents', 'father_sqrt', 'father_x_mother']\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "    plt.title('Correlation Matrix')\n",
    "    \n",
    "    # 6. Height Sqrt Father vs kid height\n",
    "    plt.subplot(3, 4, 6)\n",
    "    sns.scatterplot(data=df, x='father_sqrt', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Father Sqrt Height vs Kid Height')\n",
    "    plt.xlabel('Father Sqrt Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "    \n",
    "    # 7. Height difference between parents vs kid height\n",
    "    plt.subplot(3, 4, 7)\n",
    "    sns.scatterplot(data=df, x='height_diff_parents', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Parent Height Difference vs Kid Height')\n",
    "    plt.xlabel('Father Height - Mother Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "    \n",
    "    # 8. Distribution of average parent heights\n",
    "    plt.subplot(3, 4, 8)\n",
    "    sns.histplot(data=df, x='avg_parent_height', kde=True)\n",
    "    plt.title('Distribution of Average Parent Heights')\n",
    "    plt.xlabel('Average Parent Height')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # 9. Height by sex (violin plot)\n",
    "    plt.subplot(3, 4, 9)\n",
    "    sns.violinplot(data=df, x='sex', y='height')\n",
    "    plt.title('Height Distribution by Sex (Violin Plot)')\n",
    "    plt.xlabel('Sex')\n",
    "    plt.ylabel('Height')\n",
    "    \n",
    "    # 10. Father x Mother vs Height\n",
    "    plt.subplot(3, 4, 10)\n",
    "    sns.scatterplot(data=df, x='father_x_mother', y='height', hue='sex', alpha=0.6)\n",
    "    plt.title('Father x Mother Height vs Kid Height')\n",
    "    plt.xlabel('Father x Mother Height')\n",
    "    plt.ylabel('Kid Height')\n",
    "\n",
    "    # 11. Height percentile by sex\n",
    "    plt.subplot(3, 4, 11)\n",
    "    sns.boxplot(data=df, x='sex', y='height_percentile')\n",
    "    plt.title('Height Percentiles by Sex')\n",
    "    plt.xlabel('Sex')\n",
    "    plt.ylabel('Height Percentile')\n",
    "    \n",
    "    # 12. 3D-like scatter for both parents vs kid height\n",
    "    plt.subplot(3, 4, 12)\n",
    "    scatter = plt.scatter(df['father'], df['mother'], c=df['height'], \n",
    "                         cmap='viridis', alpha=0.6, s=30)\n",
    "    plt.colorbar(scatter, label='Kid Height')\n",
    "    plt.xlabel('Father Height')\n",
    "    plt.ylabel('Mother Height')\n",
    "    plt.title('Parent Heights vs Kid Height (Color)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "create_visualizations(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build models\n",
    "def get_split_datasets(df, features):\n",
    "    X = df[features]\n",
    "    y = df['height']\n",
    "    \n",
    "    #Split data\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "def build_models(df):\n",
    "    \"\"\"Build and evaluate multiple regression models\"\"\"\n",
    "    print(\"\\nBuilding regression models...\")\n",
    "    \n",
    "    # Define feature sets\n",
    "    feature_sets = {\n",
    "        'Basic': ['father', 'mother', 'sex_encoded'],\n",
    "        'Extended': ['father', 'mother', 'sex_encoded'],  \n",
    "        'Interaction': ['father_x_mother', 'sex_encoded'],\n",
    "        'Polynomial': ['father_sqrt', 'mother', 'sex_encoded'],\n",
    "        'Engineered': ['father', 'mother', 'sex_encoded', 'avg_parent_height', 'height_diff_parents'],\n",
    "        'All Features': ['father', 'mother', 'sex_encoded', 'nkids', 'avg_parent_height', 'height_diff_parents']\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    models = {}\n",
    " \n",
    "    for name, features in feature_sets.items():\n",
    "        print(f\"\\nTraining model: {name}\")\n",
    "        \n",
    "        # Prepare data        \n",
    "        X_train, X_test, y_train, y_test = get_split_datasets(df, features)\n",
    "        \n",
    "        # Create pipeline with scaling and regression\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('regressor', LinearRegression())\n",
    "        ])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = pipeline.predict(X_train)\n",
    "        y_pred_test = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "   \n",
    "        results[name] = {\n",
    "            'train_r2': train_r2,\n",
    "            'test_r2': test_r2,\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_mae': test_mae,\n",
    "            'features': features,\n",
    "            'y_pred_test': y_pred_test,\n",
    "            'y_test': y_test,\n",
    "        }\n",
    "        \n",
    "        models[name] = pipeline\n",
    "        \n",
    "        print(f\"  Train R²: {train_r2:.4f}\")\n",
    "        print(f\"  Test R²: {test_r2:.4f}\")\n",
    "        print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
    "        print(f\"  Test MAE: {test_mae:.4f}\")\n",
    "    \n",
    "    return results, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89094287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models\n",
    "results, models = build_models(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7817f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compare models\n",
    "def compare_models(results):\n",
    "    \"\"\"Compare all models performance\"\"\"\n",
    "    print(\"\\nModel comparison summary:\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'Test R²': [results[name]['test_r2'] for name in results.keys()],\n",
    "        'Test RMSE': [results[name]['test_rmse'] for name in results.keys()],\n",
    "        'Test MAE': [results[name]['test_mae'] for name in results.keys()],\n",
    "        'Overfitting': [results[name]['train_r2'] - results[name]['test_r2'] for name in results.keys()]\n",
    "    })\n",
    "    \n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Plot model comparison\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    margin = 0.05\n",
    "    # R² comparison\n",
    "    metrics = [ 'Test R²', 'Test RMSE', 'Overfitting' ]\n",
    "    titles = [ 'Test R² Comparison', 'Test RMSE Comparison', 'Overfitting Comparison (Train R² - Test R²)']\n",
    "    ylabels = [ 'R² Score', 'RMSE', 'Overfitting Score']\n",
    "    plot = 0\n",
    "    for i, metric in enumerate(metrics):\n",
    "        min_val = min(comparison_df[metric])\n",
    "        max_val = max(comparison_df[metric])\n",
    "        plot_margin = (max_val - min_val)*0.1\n",
    "        axes[i].bar(comparison_df['Model'], comparison_df[metric])\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].set_ylabel(ylabels[i])\n",
    "        axes[i].set_ylim(min_val*(1-plot_margin), max_val*(1+plot_margin))\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "compare_models(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Analyze best models\n",
    "def analyze_best_model(results, models, df):\n",
    "    \"\"\"Analyze the best performing model in detail\"\"\"\n",
    "    print(\"\\nDetailed analysis of best model...\")\n",
    "    \n",
    "    # Find best model based on test R²\n",
    "    best_model_name = max(results.keys(), key=lambda x: results[x]['test_r2'])\n",
    "    best_model = models[best_model_name]\n",
    "    best_results = results[best_model_name]\n",
    "\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Test R²: {best_results['test_r2']:.4f}\")\n",
    "    print(f\"Test RMSE: {best_results['test_rmse']:.4f}\")\n",
    "    print(f\"Test MAE: {best_results['test_mae']:.4f}\")\n",
    "    \n",
    "    # Get feature importance (coefficients)\n",
    "    feature_names = best_results['features']\n",
    "    coefficients = best_model.named_steps['regressor'].coef_\n",
    "    intercept = best_model.named_steps['regressor'].intercept_\n",
    "    \n",
    "    print(f\"\\nModel coefficients:\")\n",
    "    print(f\"Intercept: {intercept:.4f}\")\n",
    "    for feature, coef in zip(feature_names, coefficients):\n",
    "        print(f\"{feature}: {coef:.4f}\")\n",
    "    \n",
    "    # Create detailed plots for best model\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted - Checks Linearity Assumption\n",
    "    axes[0, 0].scatter(best_results['y_test'], best_results['y_pred_test'], alpha=0.6)\n",
    "    axes[0, 0].plot([best_results['y_test'].min(), best_results['y_test'].max()], \n",
    "                    [best_results['y_test'].min(), best_results['y_test'].max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Height')\n",
    "    axes[0, 0].set_ylabel('Predicted Height')\n",
    "    axes[0, 0].set_title(f'Linearity Check: Actual vs Predicted Heights ({best_model_name})')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Residuals plot - Checks Homoscedasticity and Linearity Assumptions\n",
    "    residuals = best_results['y_test'] - best_results['y_pred_test']\n",
    "    axes[0, 1].scatter(best_results['y_pred_test'], residuals, alpha=0.6)\n",
    "    axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Height')\n",
    "    axes[0, 1].set_ylabel('Residuals')\n",
    "    axes[0, 1].set_title('Homoscedasticity Check: Residuals Plot')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': coefficients,\n",
    "        'abs_coefficient': np.abs(coefficients)\n",
    "    }).sort_values('abs_coefficient', ascending=True)\n",
    "    \n",
    "    axes[1, 0].barh(range(len(feature_importance)), feature_importance['coefficient'])\n",
    "    axes[1, 0].set_yticks(range(len(feature_importance)))\n",
    "    axes[1, 0].set_yticklabels(feature_importance['feature'])\n",
    "    axes[1, 0].set_xlabel('Coefficient Value')\n",
    "    axes[1, 0].set_title('Feature Importance (Coefficients)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Residuals histogram - Checks Normality of residuals\n",
    "    axes[1, 1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Residuals')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Normality Check: Distribution of Residuals')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return best_model_name, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze best model\n",
    "best_model_name, best_model = analyze_best_model(results, models, df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0527fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_intervals(model, X_train, y_train, X_new, confidence_level=-0.95):\n",
    "    \"\"\"\n",
    "    Calculate confidence and prediction intervals for linear regression\n",
    "\n",
    "    Parameters: \n",
    "    - model: fitted sklearn Pipeline with StandardScalar and LinearRegression\n",
    "    - X_train: training features (original scale, before scaling)\n",
    "    - y_train: training target\n",
    "    - X_new: new data points for prediction (original scale)\n",
    "    - confidence_level: confidence level (default 0.95)\n",
    "\n",
    "    Returns:\n",
    "    - predictions: point predictions\n",
    "    - conf_lower, conf_upper: confidence interval bounds\n",
    "    - pred_lower, pred_upper: prediction interval bounds\n",
    "    \"\"\"\n",
    "\n",
    "    #Get the regression model from the pipeline\n",
    "    regressor = model.named_steps['regressor']\n",
    "    scaler = model.named_steps['scaler']\n",
    "\n",
    "    #Scale the data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    #Get predictions\n",
    "    predictions = model.predict(X_new)\n",
    "\n",
    "    #Calculate residuals and MSE from training data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    residuals = y_train - y_train_pred\n",
    "    mse = np.mean(residuals**2)\n",
    "\n",
    "    #Degrees of freedom\n",
    "    n = len(X_train)\n",
    "    dof = n - X_train_scaled.shape[1] - 1\n",
    "\n",
    "    #t-statistic for given confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    t_stat = stats.t.ppf(1 - alpha/2, dof)\n",
    "\n",
    "    #Create design matrices (and intercept column)\n",
    "    X_train_design = np.column_stack([np.ones(n), X_train_scaled])\n",
    "    X_new_design = np.column_stack([np.ones(len(X_new_scaled)), X_new_scaled])\n",
    "\n",
    "    #Calculate standard errors\n",
    "    try:\n",
    "        #Covariance matrix of parameters\n",
    "        XTX_inv = np.linalg.inv(X_train_design.T @ X_train_design)\n",
    "\n",
    "        conf_intervals = []\n",
    "        pred_intervals = []\n",
    "\n",
    "        for i in range(len(X_new_design)):\n",
    "            x_new = X_new_design[i:i+1] #keep as 2D array\n",
    "\n",
    "            #Standard error for confidence interval (mean response)\n",
    "            se_conf = np.sqrt(mse * (x_new @ XTX_inv @ x_new.T)[0, 0])\n",
    "\n",
    "            #Standard error for prediction interval (individual response)\n",
    "            se_pred = np.sqrt(mse * (1 + (x_new @ XTX_inv @ x_new.T)[0, 0]))\n",
    "\n",
    "            #Calculate intervals\n",
    "            margin_conf = t_stat * se_conf\n",
    "            margin_pred = t_stat * se_pred\n",
    "\n",
    "            conf_intervals.append([predictions[i] - margin_conf, predictions[i] + margin_conf])\n",
    "            pred_intervals.append([predictions[i] - margin_pred, predictions[i] + margin_pred])\n",
    "\n",
    "        conf_intervals = np.array(conf_intervals)\n",
    "        pred_intervals = np.array(pred_intervals)\n",
    "\n",
    "        return (predictions,\n",
    "                conf_intervals[:, 0], conf_intervals[:, 1], #conf_lower, conf_upper\n",
    "                pred_intervals[:, 0], pred_intervals[:, 1]) #pred_lower, pred_upper\n",
    "\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Could not calculate intervals due to singluar matrix\")\n",
    "        #Return NaN intervals if calculation fails\n",
    "        return (predictions, \n",
    "                np.full_like(predictions, np.nan), np.full_like(predictions, np.nan),\n",
    "                np.full_like(predictions, np.nan), np.full_like(predictions, np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_with_intervals(model, df, model_features, X_train, y_train, sample_data=None, confidence_level=0.95):\n",
    "    \"\"\"Make predictions with confidence and prediction intervals\"\"\"\n",
    "    print(f\"\\nMaking sample predictions with {confidence_level*100:.0f}% intervals...\")\n",
    "    \n",
    "    if sample_data is None:\n",
    "        # Create sample data from the dataset\n",
    "        # features = ['father', 'mother', 'sex_encoded', 'nkids', 'avg_parent_height', 'height_diff_parents', 'father_sqrt', 'father_x_mother']\n",
    "        sample_data = df.sample(5)\n",
    "    sample_data = sample_data[model_features]\n",
    "\n",
    "    #Get predictions and intervals\n",
    "    predictions, conf_lower, conf_upper, pred_lower, pred_upper = calculate_intervals(\n",
    "        model, X_train, y_train, sample_data, confidence_level\n",
    "    )\n",
    "\n",
    "    print(f\"Using features: {model_features}\")\n",
    "    print(f\"\\nPrediction Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(sample_data.head())\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "\n",
    "        #Get feature values for this prediction\n",
    "        feature_values = sample_data.iloc[i]\n",
    "        feature_str = \", \".join([f\"{feat}={val:.1f}\" for feat, val in zip(model_features, feature_values)])\n",
    "\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"  Input features: {feature_str}\")\n",
    "        print(f\"  Point prediction: {pred:.2f} inches\")\n",
    "        print(f\"  {confidence_level*100:.0f}% Confidence interval: [{conf_lower[i]:.2f}, {conf_upper[i]:.2f}] inches\")\n",
    "        print(f\"  {confidence_level*100:.0f}% Prediction interval: [{pred_lower[i]:.2f}, {pred_upper[i]:.2f}] inches\")\n",
    "        print(f\"  Confidence interval width: {conf_upper[i] - conf_lower[i]:.2f} inches\")\n",
    "        print(f\"  Prediction interval width: {pred_upper[i] - pred_lower[i]:.2f} inches\")\n",
    "\n",
    "    #Create visualization of predictions with intervals\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "    #Plot 1: Predictions with intervals\n",
    "    x_pos = range(len(predictions))\n",
    "    ax1.scatter(x_pos, predictions, color='red', s=100, zorder=5, label='Point Prediction')\n",
    "\n",
    "    #Plot confidence intervals\n",
    "    for i, x in enumerate(x_pos):\n",
    "        ax1.plot([x, x], [conf_lower[i], conf_upper[i]], 'b-', linewidth=3, alpha=0.7, label='Confidence Interval' if i == 0 else \"\")\n",
    "\n",
    "    #Plot prediction intervals\n",
    "    for i, x in enumerate(x_pos):\n",
    "        ax1.plot([x, x], [pred_lower[i], pred_upper[i]], 'g-', linewidth=2, alpha=0.7, label='Prediction Interval' if i == 0 else \"\")\n",
    "\n",
    "    ax1.set_xlabel('Sample Number')\n",
    "    ax1.set_ylabel('Height (inches)')\n",
    "    ax1.set_title('Predictions with Confidence and Prediction Intervals')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels([f'Sample {i+1}' for i in x_pos])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Interval widths comparison\n",
    "    conf_widths = conf_upper - conf_lower\n",
    "    pred_widths = pred_upper - pred_lower\n",
    "    \n",
    "    x_offset = np.arange(len(predictions))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar(x_offset - width/2, conf_widths, width, label='Confidence Interval Width', alpha=0.7)\n",
    "    ax2.bar(x_offset + width/2, pred_widths, width, label='Prediction Interval Width', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Sample Number')\n",
    "    ax2.set_ylabel('Interval Width (inches)')\n",
    "    ax2.set_title('Interval Widths Comparison')\n",
    "    ax2.set_xticks(x_offset)\n",
    "    ax2.set_xticklabels([f'Sample {i+1}' for i in range(len(predictions))])\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return results for further analysis if needed\n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'conf_lower': conf_lower,\n",
    "        'conf_upper': conf_upper,\n",
    "        'pred_lower': pred_lower,\n",
    "        'pred_upper': pred_upper,\n",
    "        'sample_data': sample_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31236574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sample predictions using the best model's features\n",
    "best_model_features = results[best_model_name]['features']\n",
    "\n",
    "#Get training data for interval calculations\n",
    "X_train, X_test, y_train, y_test = get_split_datasets(df_clean, best_model_features)\n",
    "\n",
    "prediction_results = make_predictions_with_intervals(\n",
    "    best_model, df_clean, best_model_features, X_train, y_train\n",
    ")\n",
    "\n",
    "print(f\"\\nAnalysis complete! Best model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the height of a child whose father is 50 inches and whose mother is 70 inches tall.\n",
    "max_family_num = max(df['family'])\n",
    "\n",
    "example_data = pd.DataFrame([\n",
    "    {'family': int(max_family_num)+1, 'father': 70, 'mother': 50, 'nkids': 2, 'sex': 'M', 'height': 0},\n",
    "    {'family': int(max_family_num)+1, 'father': 70, 'mother': 50, 'nkids': 2, 'sex': 'F', 'height': 0},\n",
    "                           ])\n",
    "example_df_clean, _ignore = clean_and_preprocess_data(example_data)\n",
    "\n",
    "#Get training data for interval calculations\n",
    "X_train, X_test, y_train, y_test = get_split_datasets(df_clean, best_model_features)\n",
    "\n",
    "example_prediction_results = make_predictions_with_intervals(\n",
    "    best_model, df_clean, best_model_features, X_train, y_train, sample_data=example_df_clean, confidence_level=0.98\n",
    ")\n",
    "\n",
    "print(f\"\\nAnalysis complete! Best model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0dd364",
   "metadata": {},
   "source": [
    "How much do you trust this prediction and why?\n",
    "The metrics provide an R² on test data indicating for the Interaction model 62% of results are explained by independent variables \n",
    "This model has the highest R² and lowest RMSE, and Overfitting score.\n",
    "Test R²: 0.6213\n",
    "Test RMSE: 2.1323\n",
    "Test MAE: 1.6093\n",
    "Overfitting: 0.0189\n",
    "This model is also trustworthy because it passes the assumptions of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d18f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Make predictions with prediction and confidence intervals\n",
    "def calculate_height_probabilities(model, model_features, X_train, y_train, parent_heights_df, target_heights, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Calculate probabilities of achieving certain heights given parental heights and sex\n",
    "    \n",
    "    Parameters:\n",
    "    - model: fitted sklearn Pipeline\n",
    "    - X_train, y_train: training data for interval calculation\n",
    "    - parent_heights_df: df with 'father' and 'mother' heights\n",
    "    - sex: 'M' or 'F' (or 0/1 if using encoded values)\n",
    "    - target_heights: list of heights to calculate probabilities for\n",
    "    - confidence_level: confidence level for intervals\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with probabilities and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the input data\n",
    "    # Determine which features the model expects\n",
    "    regressor = model.named_steps['regressor']\n",
    "    n_features = len(regressor.coef_)\n",
    "    \n",
    "    # Create feature vector based on model requirements\n",
    "    X_new, _ignore = clean_and_preprocess_data(parent_heights_df)\n",
    "    X_new = X_new[model_features]\n",
    "    \n",
    "    # Get prediction and intervals\n",
    "    pred, conf_lower, conf_upper, pred_lower, pred_upper = calculate_intervals(\n",
    "        model, X_train, y_train, X_new, confidence_level\n",
    "    )\n",
    "    \n",
    "    prediction = pred[0]\n",
    "    pred_interval_lower = pred_lower[0]\n",
    "    pred_interval_upper = pred_upper[0]\n",
    "    \n",
    "    # Calculate residuals from training data to estimate standard deviation\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    residuals = y_train - y_train_pred\n",
    "    residual_std = np.std(residuals)\n",
    "    \n",
    "    # Calculate probabilities using normal distribution assumption\n",
    "    # (prediction intervals already account for prediction uncertainty)\n",
    "    results = {\n",
    "        'prediction': prediction,\n",
    "        'pred_interval_lower': pred_interval_lower,\n",
    "        'pred_interval_upper': pred_interval_upper,\n",
    "        'residual_std': residual_std,\n",
    "        'parent_heights': parent_heights_df.loc[0],\n",
    "        'sex': parent_heights_df.loc[0, 'sex'],\n",
    "        'probabilities': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nHeight Probability Analysis\")\n",
    "    print(f\"Parent heights: Father = {parent_heights_df.loc[0, 'father']:.1f}\\\", Mother = {parent_heights_df.loc[0, 'mother']:.1f}\\\"\")\n",
    "    print(f\"Child sex: {'Male' if parent_heights_df.loc[0, 'sex'] == 'M' else 'Female'}\")\n",
    "    print(f\"Predicted height: {prediction:.2f}\\\"\")\n",
    "    print(f\"95% Prediction interval: [{pred_interval_lower:.2f}\\\", {pred_interval_upper:.2f}\\\"]\")\n",
    "    print(f\"Prediction standard deviation: {residual_std:.2f}\\\"\")\n",
    "    print(\"\\nProbability Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for target_height in target_heights:\n",
    "        # Calculate z-score using the prediction as mean and residual std as standard deviation\n",
    "        z_score = (target_height - prediction) / residual_std\n",
    "        \n",
    "        # Calculate probabilities using standard normal distribution\n",
    "        prob_less_than = stats.norm.cdf(z_score)\n",
    "        prob_greater_than = 1 - prob_less_than\n",
    "        prob_exactly = stats.norm.pdf(z_score) / residual_std  # Density at that point\n",
    "        \n",
    "        # Store results\n",
    "        results['probabilities'][target_height] = {\n",
    "            'prob_less_than': prob_less_than,\n",
    "            'prob_greater_than': prob_greater_than,\n",
    "            'prob_density': prob_exactly,\n",
    "            'z_score': z_score\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nTarget height: {target_height:.1f}\\\"\")\n",
    "        print(f\"  Probability height < {target_height:.1f}\\\": {prob_less_than:.3f} ({prob_less_than*100:.1f}%)\")\n",
    "        print(f\"  Probability height > {target_height:.1f}\\\": {prob_greater_than:.3f} ({prob_greater_than*100:.1f}%)\")\n",
    "        print(f\"  Z-score: {z_score:.2f}\")\n",
    "        \n",
    "        # Add percentile information\n",
    "        if abs(z_score) <= 3:  # Only show percentile for reasonable values\n",
    "            percentile = prob_less_than * 100\n",
    "            print(f\"  This height is at the {percentile:.1f}th percentile\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_height_probability_distribution(prob_results):\n",
    "    \"\"\"\n",
    "    Plot the probability distribution of heights with target heights marked\n",
    "    \"\"\"\n",
    "    prediction = prob_results['prediction']\n",
    "    std = prob_results['residual_std']\n",
    "    parent_heights = prob_results['parent_heights']\n",
    "    sex = prob_results['sex']\n",
    "    pred_lower = prob_results['pred_interval_lower']\n",
    "    pred_upper = prob_results['pred_interval_upper']\n",
    "    \n",
    "    # Create height range for plotting\n",
    "    height_range = np.linspace(prediction - 4*std, prediction + 4*std, 1000)\n",
    "    \n",
    "    # Calculate probability density\n",
    "    prob_density = stats.norm.pdf(height_range, prediction, std)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Plot 1: Probability density function\n",
    "    ax1.plot(height_range, prob_density, 'b-', linewidth=2, label='Probability Density')\n",
    "    ax1.fill_between(height_range, prob_density, alpha=0.3, color='lightblue')\n",
    "    \n",
    "    # Mark prediction interval\n",
    "    ax1.axvline(pred_lower, color='green', linestyle='--', alpha=0.7, label=f'95% Prediction Interval')\n",
    "    ax1.axvline(pred_upper, color='green', linestyle='--', alpha=0.7)\n",
    "    ax1.fill_between(height_range, prob_density, \n",
    "                     where=(height_range >= pred_lower) & (height_range <= pred_upper),\n",
    "                     alpha=0.5, color='lightgreen', label='95% Prediction Range')\n",
    "    \n",
    "    # Mark predicted height\n",
    "    ax1.axvline(prediction, color='red', linewidth=2, label=f'Predicted Height ({prediction:.1f}\\\")')\n",
    "    \n",
    "    # Mark target heights if any were calculated\n",
    "    colors = ['orange', 'purple', 'brown', 'pink', 'gray']\n",
    "    for i, (target_height, prob_info) in enumerate(prob_results['probabilities'].items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        ax1.axvline(target_height, color=color, linestyle=':', linewidth=2, \n",
    "                   label=f'Target: {target_height:.1f}\\\" (P>{target_height:.1f}\\\" = {prob_info[\"prob_greater_than\"]:.3f})')\n",
    "    \n",
    "    ax1.set_xlabel('Height (inches)')\n",
    "    ax1.set_ylabel('Probability Density')\n",
    "    ax1.set_title(f'Height Distribution Prediction\\n'\n",
    "                  f'Father: {parent_heights[\"father\"]:.1f}\\\", Mother: {parent_heights[\"mother\"]:.1f}\\\", '\n",
    "                  f'Child: {\"Male\" if sex == \"M\" else \"Female\"}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Cumulative probability\n",
    "    cumulative_prob = stats.norm.cdf(height_range, prediction, std)\n",
    "    ax2.plot(height_range, cumulative_prob, 'r-', linewidth=2, label='Cumulative Probability')\n",
    "    \n",
    "    # Mark key percentiles\n",
    "    percentiles = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "    percentile_heights = stats.norm.ppf(percentiles, prediction, std)\n",
    "    \n",
    "    for p, h in zip(percentiles, percentile_heights):\n",
    "        ax2.axhline(p, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax2.axvline(h, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax2.plot(h, p, 'ko', markersize=6)\n",
    "        ax2.annotate(f'{p*100:.0f}th percentile\\n({h:.1f}\\\")', \n",
    "                    xy=(h, p), xytext=(10, 10), textcoords='offset points',\n",
    "                    fontsize=8, ha='left')\n",
    "    \n",
    "    # Mark target heights on cumulative plot\n",
    "    for i, (target_height, prob_info) in enumerate(prob_results['probabilities'].items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        prob_less = prob_info['prob_less_than']\n",
    "        ax2.plot(target_height, prob_less, 'o', color=color, markersize=8)\n",
    "        ax2.annotate(f'{target_height:.1f}\\\": {prob_less:.3f}', \n",
    "                    xy=(target_height, prob_less), xytext=(10, -10), \n",
    "                    textcoords='offset points', fontsize=8, ha='left', color=color)\n",
    "    \n",
    "    ax2.set_xlabel('Height (inches)')\n",
    "    ax2.set_ylabel('Cumulative Probability')\n",
    "    ax2.set_title('Cumulative Height Distribution')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def height_probability_analysis(model, model_features, X_train, y_train, scenarios):\n",
    "    \"\"\"\n",
    "    Analyze height probabilities for multiple scenarios\n",
    "    \n",
    "    Parameters:\n",
    "    - model: fitted model\n",
    "    - X_train, y_train: training data\n",
    "    - scenarios: list of dicts with 'father', 'mother', 'sex', 'target_heights'\n",
    "    \n",
    "    Example:\n",
    "    scenarios = [\n",
    "        {\n",
    "            'father': 72.0, 'mother': 66.0, 'sex': 'M', \n",
    "            'target_heights': [70, 72, 74, 76]\n",
    "        },\n",
    "        {\n",
    "            'father': 68.0, 'mother': 64.0, 'sex': 'F', \n",
    "            'target_heights': [62, 64, 66, 68]\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SCENARIO {i+1}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        target_heights = scenario['target_heights']\n",
    "        parent_heights_df = pd.DataFrame({\n",
    "            'father': scenario['father'], \n",
    "            'mother': scenario['mother'], \n",
    "            'nkids': 1, \n",
    "            'sex': scenario['sex'],\n",
    "            'height': 0\n",
    "        }, index=[0])\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        prob_results = calculate_height_probabilities(\n",
    "            model, model_features, X_train, y_train, parent_heights_df, target_heights\n",
    "        )\n",
    "        \n",
    "        all_results.append(prob_results)\n",
    "        \n",
    "        # Create visualization\n",
    "        plot_height_probability_distribution(prob_results)\n",
    "    \n",
    "    return all_results\n",
    "    \"\"\"Compare all models performance\"\"\"\n",
    "    print(\"\\nModel comparison summary:\")\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'Test R²': [results[name]['test_r2'] for name in results.keys()],\n",
    "        'Test RMSE': [results[name]['test_rmse'] for name in results.keys()],\n",
    "        'Test MAE': [results[name]['test_mae'] for name in results.keys()],\n",
    "        'Overfitting': [results[name]['train_r2'] - results[name]['test_r2'] for name in results.keys()]\n",
    "    })\n",
    "    \n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Plot model comparison\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # R² comparison\n",
    "    axes[0].bar(comparison_df['Model'], comparison_df['Test R²'])\n",
    "    axes[0].set_title('Test R² Score Comparison')\n",
    "    axes[0].set_ylabel('R² Score')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # RMSE comparison\n",
    "    axes[1].bar(comparison_df['Model'], comparison_df['Test RMSE'])\n",
    "    axes[1].set_title('Test RMSE Comparison')\n",
    "    axes[1].set_ylabel('RMSE')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Overfitting comparison\n",
    "    axes[2].bar(comparison_df['Model'], comparison_df['Overfitting'])\n",
    "    axes[2].set_title('Overfitting Comparison (Train R² - Test R²)')\n",
    "    axes[2].set_ylabel('Overfitting Score')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example probability analysis\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PROBABILITY ANALYSIS EXAMPLES\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "#Define example scenarios\n",
    "example_scenarios = [\n",
    "    {\n",
    "        'father': 72.0, 'mother': 66.0, 'sex':'M',\n",
    "        'target_heights': [70, 72, 74, 76],\n",
    "        'description': 'Tall father, average mother, male child'\n",
    "    },\n",
    "    {\n",
    "        'father': 68.0, 'mother': 64.0, 'sex':'F',\n",
    "        'target_heights': [62, 64, 66, 68],\n",
    "        'description': 'Average father, shorter mother, female child'\n",
    "    }\n",
    "]\n",
    "\n",
    "#Run probability analysis\n",
    "probability_results = height_probability_analysis(best_model, best_model_features, X_train, y_train, example_scenarios)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
